{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A random forest model to predict the artist (Modest Mouse or Violent Femmes) by a snippet of lyrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries:\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get linkslist from URL, save as html to disk and return as text_file: \n",
    "\n",
    "def get_linklist__to_disk(URL:str, html_filename:str):\n",
    "    \n",
    "    \"\"\"scrape linklist from url, \n",
    "       save html.file to disk, returns textfile of html\"\"\"\n",
    "    \n",
    "    response= requests.get(URL)\n",
    "    print(response.status_code)\n",
    "    html_file = response.text\n",
    "    with open(f'{html_filename}.html', 'w') as file:\n",
    "        file.write(html_file)\n",
    "    return html_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# get linklist for modest mouse, save to disk and return as text_file :\n",
    "\n",
    "modest_html = get_linklist__to_disk(\"https://www.lyrics.com/artist/Modest-Mouse/200044\", \"modest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# get linklist for violent femmes, save to disk and return as text_file :\n",
    "\n",
    "violent_html = get_linklist__to_disk(\"https://www.lyrics.com/artist/Violent-Femmes/5767\", \"violent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extract songlinks  with regEx/BeautifulSoup, complete URL and check for duplicates: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Violent femmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RegEx pattern: \n",
    "pattern_vf = 'href=\"(\\/lyric.+?)\"' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linklist_url_complete(pattern, textfilename):\n",
    "    \n",
    "    \"\"\" returns list with complete URLs of songlinks\"\"\"\n",
    "    \n",
    "    songlist = re.findall(pattern, textfilename)\n",
    "    complete =[]\n",
    "    #complete links in list with missing URL part:\n",
    "    for link in songlist: \n",
    "        complete.append(\"https://www.lyrics.com\" + link)\n",
    "    return complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_vf = linklist_url_complete(pattern_vf, violent_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate files:             \n",
    "def check_dupes(linklist):\n",
    "\n",
    "\n",
    "    s = set()\n",
    "    for item in linklist:\n",
    "        s.add(item)\n",
    "    if (len(linklist)-(len(s)) == 0):\n",
    "                         print(\"no duplicates\")\n",
    "    else:\n",
    "                         print(\"duplicates found\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no duplicates\n"
     ]
    }
   ],
   "source": [
    "check_dupes(songs_vf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modest Mouse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create beautiful soup object:\n",
    "modest_soup = BeautifulSoup(modest_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser:\n",
    "parser = \"soup.find_all(attrs = {'class' : 'tdata-ext'})[0].find_all('tr')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list with complete song links (excluding album links) with beautiful soup:\n",
    "def linklist_complete_BS(parser:str):\n",
    "    \n",
    "    \"\"\" get complete URL for MM songs scraped at lyrics.com\"\"\"\n",
    "    songs = []    \n",
    "    for element in parser:      \n",
    "   \n",
    "        try:\n",
    "            songs.append(element.a.get('href'))\n",
    "       \n",
    "        except AttributeError:\n",
    "            pass\n",
    "    \n",
    "    complete =[]\n",
    "    for link in songs: \n",
    "        complete.append(\"https://www.lyrics.com\" + link)\n",
    "    return complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_mm = linklist_complete_BS(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no duplicates\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate files    \n",
    "check_dupes(songs_mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get html files for each song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function to request all html files in songlink-list and download as html files to disk: \n",
    "def get_songs_html(linklist, artist:str, artistinitials:str):\n",
    "    \"\"\"scrapes and writes html file for each songlyric to disk\"\"\"\n",
    "\n",
    "    num = 1\n",
    "    for link in linklist:\n",
    "    \n",
    "        response = requests.get(link)\n",
    "        song_html = response.text\n",
    "        with open(f'/Users/krystanafoh/lyrics/{artist}/{num}_{artistinitials}_test.html', 'w') as file:\n",
    "            file.write(song_html)\n",
    "        num = num + 1\n",
    "        time.sleep(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# violent femmes:\n",
    "#get_songs_html(songs_vf, \"violentfemmes\", \"vf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modest mouse:\n",
    "#get_songs_html(songs_mm, \"modestmouse\", \"mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  extract songlyrics of html files and safe each to textfile: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyrics_to_text(linklist, artist:str, artistinitials:str):\n",
    "    \"\"\"extract and safe lyrics of each song to textfile\"\"\"\n",
    "    \n",
    "    num = 1\n",
    "    for i in range(len(linklist)):\n",
    "        \n",
    "        filename = (f'/Users/krystanafoh/lyrics/{artist}/{num}_{artistinitials}')\n",
    "# open html file\n",
    "        html = open(f'{filename}.html')\n",
    "# create beautiful soup object\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "# get song text\n",
    "        text = soup.find_all('pre', attrs = {'class' : 'lyric-body'})[0].get_text()\n",
    "# safe song text to text file: \n",
    "        with open(f'{filename}.text', 'w') as file:\n",
    "            file.write(text)\n",
    "        num = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modest mouse:\n",
    "#lyrics_to_text(songs_mm, \"modestmouse\", \"mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# violent femmes: \n",
    "#lyrics_to_text(songs_vf, \"violentfemmes\", \"vf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create lists of strings for each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyrics_to_list(path:str):\n",
    "    \"\"\"returns a list of lyricstrings\"\"\"\n",
    "\n",
    "    textfile = glob.glob(os.path.join(path, '*.text'), recursive=False)\n",
    "\n",
    "    lyrics = []\n",
    "   \n",
    "    for file_path in textfile:\n",
    "        with open(file_path) as f_input:\n",
    "            lyrics.append(f_input.read())\n",
    "\n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of Modest Mouse songtexts: \n",
    "path = '/Users/krystanafoh/lyrics/modestmouse/'\n",
    "list_mm = lyrics_to_list(path)\n",
    "len(list_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of Violent Femmes songtexts: \n",
    "path2 = '/Users/krystanafoh/lyrics/violentfemmes/'\n",
    "list_vf = lyrics_to_list(path2)\n",
    "len(list_vf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create corpus and do test-train-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = list_mm + list_vf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "788"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CORPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"Modest Mouse\"] * len(list_mm) + [\"Violent Femmes\"] * len(list_vf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = CORPUS\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-split: \n",
    "X_test, X_train, y_test, y_train = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Feature Engineering: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"cleans up text with RegEx, replacing \"n'\" with \"ng\", \n",
    "    removing punctuation except \"'\", replaceing \"\\n\" with whitespace, lowercaseing, \n",
    "    removing double whitespace\"\"\"\n",
    "    \n",
    "    # replace \"n'\" with ng:\n",
    "    text = re.sub(\"\\w(n')\\s\",\"\", text)   \n",
    "        \n",
    "        \n",
    "    #remove punctuation:\n",
    "    text = re.sub(\"[^\\w\\s']\",\"\",text)\n",
    "    \n",
    "    # replace \"\\n\" by whitespace : \n",
    "    text = re.sub(\"\\\\n\", \" \", text)\n",
    "    \n",
    "   \n",
    "    # lowercase    \n",
    "    text = text.lower()\n",
    "    \n",
    "    #removing duble whitespaces:\n",
    "    text = re.sub(\"\\s+\",\" \", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_list(X_split):\n",
    "    \"\"\"applies clean_text function to every item in list (of songtexts)\"\"\"\n",
    "    \n",
    "    clean_list = []\n",
    "    for song in X_split:\n",
    "        clean_list.append(clean_text(song))\n",
    "    return clean_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rf_pipe = Pipeline([\n",
    "    (\"cleaning_text\", FunctionTransformer(clean_list)), \n",
    "    (\"vectorize\", TfidfVectorizer(ngram_range=(1,1), smooth_idf=True, stop_words='english')),\n",
    "    (\"model\",RandomForestClassifier(n_estimators= 800, min_samples_split=2, min_samples_leaf=2, max_depth=50, max_features='sqrt', bootstrap=False, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Grid Search: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of trees in random forest:\n",
    "#n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "## Number of features to consider at every split:\n",
    "#max_features = ['auto', 'sqrt']\n",
    "\n",
    "## Maximum number of levels in tree:\n",
    "#max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "#max_depth.append(None)\n",
    "\n",
    "## Minimum number of samples required to split a node:\n",
    "##min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node:\n",
    "#min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "## Method of selecting samples for training each tree:\n",
    "#bootstrap = [True, False]\n",
    "\n",
    "## Create the random grid:\n",
    "#random_grid = {'n_estimators': n_estimators,\n",
    "#               'max_features': max_features,\n",
    " #              'max_depth': max_depth,\n",
    "  #             'min_samples_split': min_samples_split,\n",
    "   #            'min_samples_leaf': min_samples_leaf,\n",
    "    #           'bootstrap': bootstrap}\n",
    "#print(random_grid)\n",
    "\n",
    "#{'bootstrap': [True, False],\n",
    "# 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "# 'max_features': ['auto', 'sqrt'],\n",
    "# 'min_samples_leaf': [1, 2, 4],\n",
    "# 'min_samples_split': [2, 5, 10],\n",
    "# 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters:\n",
    "\n",
    "# First create the base model to tune:\n",
    "##rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores:\n",
    "##rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model:\n",
    "##rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  X train fit and evaluation of model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cleaning_text',\n",
       "                 FunctionTransformer(func=<function clean_list at 0x124746940>)),\n",
       "                ('vectorize', TfidfVectorizer(stop_words='english')),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(bootstrap=False, max_depth=50,\n",
       "                                        max_features='sqrt', min_samples_leaf=2,\n",
       "                                        n_estimators=800, random_state=42))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit pipeline on X_train: \n",
    "clean_rf_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on X_train: \n",
    "y_pred_train = clean_rf_pipe.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Modest Mouse       1.00      1.00      1.00       101\n",
      "Violent Femmes       1.00      1.00      1.00        96\n",
      "\n",
      "      accuracy                           1.00       197\n",
      "     macro avg       1.00      1.00      1.00       197\n",
      "  weighted avg       1.00      1.00      1.00       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report: \n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training score: \n",
    "clean_rf_pipe.score(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8366666666666667"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validation: \n",
    "cross_val_score(clean_rf_pipe, X_train, y_train, cv=20).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  predictions on X_test and further evaluations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on  X_test: \n",
    "y_pred_test = clean_rf_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Modest Mouse       0.86      0.94      0.90       301\n",
      "Violent Femmes       0.93      0.84      0.88       290\n",
      "\n",
      "      accuracy                           0.89       591\n",
      "     macro avg       0.90      0.89      0.89       591\n",
      "  weighted avg       0.90      0.89      0.89       591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8917089678510999"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test score: \n",
    "clean_rf_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8366666666666667"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validation: \n",
    "cross_val_score(clean_rf_pipe, X_train, y_train, cv=20).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix:\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_test), annot=True, fmt=\".0f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use pipeline on guessed band lyrics: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62423776, 0.37576224]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_rf_pipe.predict_proba([\"a long ride for someone\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66326048, 0.33673952]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_rf_pipe.predict_proba([\"my car\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59141675, 0.40858325]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_rf_pipe.predict_proba([\"float on float on float on\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53033066, 0.46966934]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_rf_pipe.predict_proba([\"nightmares\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52902408, 0.47097592]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_rf_pipe.predict_proba([\"getting together with you\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.53699813 0.46300187]]\n"
     ]
    }
   ],
   "source": [
    "print(clean_rf_pipe.predict_proba([\"jaksfnaksljdbflasdkjf\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.59141675 0.40858325]]\n"
     ]
    }
   ],
   "source": [
    "print(clean_rf_pipe.predict_proba([\"float on float on float on float on float on float on float on float on float on\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.504554 0.495446]]\n",
      "ðŸ˜¡\n"
     ]
    }
   ],
   "source": [
    "print(clean_rf_pipe.predict_proba([\"like a blister in the sun\"]))\n",
    "print(\"\\N{pouting face}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51899321 0.48100679]]\n",
      "ðŸ˜¡\n"
     ]
    }
   ],
   "source": [
    "print(clean_rf_pipe.predict_proba([\"blister blister blister\"]))\n",
    "print(\"\\N{pouting face}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
